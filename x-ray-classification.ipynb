{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nfrom torch.utils.tensorboard import SummaryWriter  # TensorBoard-hoz\nimport torch.nn.functional as F\n# from ann_visualizer.visualize import ann_viz\n# import visualkeras\nimport tensorflow as tf\n# from torchviz import make_dot\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import TensorBoard","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:58:51.063288Z","iopub.execute_input":"2023-11-21T13:58:51.064197Z","iopub.status.idle":"2023-11-21T13:59:14.997499Z","shell.execute_reply.started":"2023-11-21T13:58:51.064162Z","shell.execute_reply":"2023-11-21T13:59:14.996411Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Elérési útvonalak\ndata_dir = \"/kaggle/input/chest-xray-pneumonia/chest_xray/\"\ntrain_dir = data_dir + \"train/\"\nval_dir = data_dir + \"val/\"\ntest_dir = data_dir + \"test/\"\n\n# Transzformációs paraméterek\nimage_size = (224, 224)\nbatch_size = 112\n\n# Kép adatgenerátor létrehozása\ntrain_datagen = ImageDataGenerator(rescale=1./255)\nval_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# Train Dataset létrehozása\ntrain_dataset = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='binary'  # Mivel két osztály van: \"PNEUMONIA\" és \"NORMAL\"\n)\n\n# Validation Dataset létrehozása\nval_dataset = val_datagen.flow_from_directory(\n    val_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='binary'\n)\n\n# Test Dataset létrehozása\ntest_dataset = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode='binary'\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:59:14.999538Z","iopub.execute_input":"2023-11-21T13:59:15.000234Z","iopub.status.idle":"2023-11-21T13:59:18.285055Z","shell.execute_reply.started":"2023-11-21T13:59:15.000198Z","shell.execute_reply":"2023-11-21T13:59:18.284253Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Found 5216 images belonging to 2 classes.\nFound 16 images belonging to 2 classes.\nFound 624 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras import layers, models\n\n# Modell létrehozása\nfrom tensorflow.keras import layers, models\n\nmodel = models.Sequential()\n\n# Block 1\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(224, 224, 3), padding='same'))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\nmodel.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n\n# Block 2\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\nmodel.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n\n# Block 3\nmodel.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\nmodel.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\nmodel.add(layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\nmodel.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n\n# Block 4\nmodel.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\nmodel.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\nmodel.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\nmodel.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n\n# Block 5\nmodel.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\nmodel.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\nmodel.add(layers.Conv2D(512, (3, 3), activation='relu', padding='same'))\nmodel.add(layers.MaxPooling2D((2, 2), strides=(2, 2)))\n\n# Flatten and fully connected layers\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(4096, activation='sigmoid'))\nmodel.add(layers.Dense(4096, activation='sigmoid'))\n\n\n# Output layer with Sigmoid activation for binary classification\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:59:18.286435Z","iopub.execute_input":"2023-11-21T13:59:18.287059Z","iopub.status.idle":"2023-11-21T13:59:29.087934Z","shell.execute_reply.started":"2023-11-21T13:59:18.287021Z","shell.execute_reply":"2023-11-21T13:59:29.087005Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 224, 224, 64)      1792      \n                                                                 \n conv2d_1 (Conv2D)           (None, 224, 224, 64)      36928     \n                                                                 \n max_pooling2d (MaxPooling2  (None, 112, 112, 64)      0         \n D)                                                              \n                                                                 \n conv2d_2 (Conv2D)           (None, 112, 112, 128)     73856     \n                                                                 \n conv2d_3 (Conv2D)           (None, 112, 112, 128)     147584    \n                                                                 \n max_pooling2d_1 (MaxPoolin  (None, 56, 56, 128)       0         \n g2D)                                                            \n                                                                 \n conv2d_4 (Conv2D)           (None, 56, 56, 256)       295168    \n                                                                 \n conv2d_5 (Conv2D)           (None, 56, 56, 256)       590080    \n                                                                 \n conv2d_6 (Conv2D)           (None, 56, 56, 256)       590080    \n                                                                 \n max_pooling2d_2 (MaxPoolin  (None, 28, 28, 256)       0         \n g2D)                                                            \n                                                                 \n conv2d_7 (Conv2D)           (None, 28, 28, 512)       1180160   \n                                                                 \n conv2d_8 (Conv2D)           (None, 28, 28, 512)       2359808   \n                                                                 \n conv2d_9 (Conv2D)           (None, 28, 28, 512)       2359808   \n                                                                 \n max_pooling2d_3 (MaxPoolin  (None, 14, 14, 512)       0         \n g2D)                                                            \n                                                                 \n conv2d_10 (Conv2D)          (None, 14, 14, 512)       2359808   \n                                                                 \n conv2d_11 (Conv2D)          (None, 14, 14, 512)       2359808   \n                                                                 \n conv2d_12 (Conv2D)          (None, 14, 14, 512)       2359808   \n                                                                 \n max_pooling2d_4 (MaxPoolin  (None, 7, 7, 512)         0         \n g2D)                                                            \n                                                                 \n flatten (Flatten)           (None, 25088)             0         \n                                                                 \n dense (Dense)               (None, 4096)              102764544 \n                                                                 \n dense_1 (Dense)             (None, 4096)              16781312  \n                                                                 \n dense_2 (Dense)             (None, 1)                 4097      \n                                                                 \n=================================================================\nTotal params: 134264641 (512.18 MB)\nTrainable params: 134264641 (512.18 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Download ngrok\n# !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n# !unzip ngrok-stable-linux-amd64.zip\n\n# Start TensorBoard in the background\n# get_ipython().system_raw(f'tensorboard --logdir /kaggle/working/ --host 0.0.0.0 --port 6006 &')\n\n# Get the public URL using ngrok\n# get_ipython().system_raw('./ngrok http 6007 &')\n\n# Import the time module\n# import time\n# time.sleep(1.0)\n\n# Print the public URL\n# !curl -s http://localhost:4040/api/tunnels | python3 -c 'import sys, json; print(\"TensorBoard will be available at the following URL: \" +json.load(sys.stdin)[\"tunnels\"][0][\"public_url\"])'\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:59:29.089865Z","iopub.execute_input":"2023-11-21T13:59:29.090159Z","iopub.status.idle":"2023-11-21T13:59:29.094712Z","shell.execute_reply.started":"2023-11-21T13:59:29.090133Z","shell.execute_reply":"2023-11-21T13:59:29.093791Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n\n# Tanulási ráta dinamikussá tétele a teljesítmény alapján\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.01, patience=3, min_lr=1e-6)\n\n# Modell fordítása (compile)\nmodel.compile(\n    optimizer=Adam(\n        learning_rate=0.002,  # Tanulási ráta\n        beta_1=0.5,  # Exponenciális mozgóátlag decay faktora az első momentumra\n        beta_2=0.999,  # Exponenciális mozgóátlag decay faktora a második momentumra\n        epsilon=1e-07,  # Az osztóhoz hozzáadott kis konstans\n        amsgrad=False,  # Amsgrad algoritmus alkalmazása\n        # weight_decay=None,  # Súlycsökkentés (L2 súlycsökkentés) - nem támogatott\n        clipnorm=None,  # Szabályozza a súlyvektornormákat\n        clipvalue=None,  # Szabályozza a súlyértékeket\n        global_clipnorm=None,  # Szabályozza az összes súlyvektornormát\n        use_ema=False,  # Exponenciális mozgóátlag használata a súlyok frissítéséhez\n        ema_momentum=0.8,  # Az exponenciális mozgóátlag momentuma\n        ema_overwrite_frequency=None,  # Az exponenciális mozgóátlag súlyainak felülírásának gyakorisága\n        jit_compile=True,  # Just-In-Time fordítás (JIT) alkalmazása\n        name='Adam'  # Az optimizer neve\n    ),\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\n# ModelCheckpoint callback létrehozása a legjobb súlyok mentéséhez\ncheckpoint = ModelCheckpoint(\"best_weights\", save_best_only=True)\n\n# Modell tanítása\nnum_epochs_fine_tune = 9999\n\n# Train\nhistory_fine_tune = model.fit(\n    train_dataset,\n    epochs=num_epochs_fine_tune,\n    validation_data=val_dataset,\n    callbacks=[checkpoint, reduce_lr],\n    verbose=1                        \n)\n\n# Metrikák kinyerése a history objektumból\ntrain_loss = history_fine_tune.history['loss']\ntrain_accuracy = history_fine_tune.history['accuracy']\nval_loss = history_fine_tune.history['val_loss']\nval_accuracy = history_fine_tune.history['val_accuracy']\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T13:59:29.096168Z","iopub.execute_input":"2023-11-21T13:59:29.096706Z","iopub.status.idle":"2023-11-21T14:00:21.602379Z","shell.execute_reply.started":"2023-11-21T13:59:29.096670Z","shell.execute_reply":"2023-11-21T14:00:21.600773Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Epoch 1/9999\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m num_epochs_fine_tune \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m9999\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m history_fine_tune \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs_fine_tune\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m                        \u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Metrikák kinyerése a history objektumból\u001b[39;00m\n\u001b[1;32m     45\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m history_fine_tune\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential/max_pooling2d_2/MaxPool' defined at (most recent call last):\n    File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/opt/conda/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/opt/conda/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_47/2157821120.py\", line 36, in <module>\n      history_fine_tune = model.fit(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1080, in train_step\n      y_pred = self(x, training=True)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 569, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/sequential.py\", line 405, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/layers/pooling/base_pooling2d.py\", line 84, in call\n      outputs = self.pool_function(\nNode: 'sequential/max_pooling2d_2/MaxPool'\nOOM when allocating tensor with shape[224,256,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential/max_pooling2d_2/MaxPool}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_3552]"],"ename":"ResourceExhaustedError","evalue":"Graph execution error:\n\nDetected at node 'sequential/max_pooling2d_2/MaxPool' defined at (most recent call last):\n    File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/opt/conda/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/opt/conda/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/opt/conda/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/opt/conda/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_47/2157821120.py\", line 36, in <module>\n      history_fine_tune = model.fit(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1080, in train_step\n      y_pred = self(x, training=True)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 569, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/sequential.py\", line 405, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1150, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/layers/pooling/base_pooling2d.py\", line 84, in call\n      outputs = self.pool_function(\nNode: 'sequential/max_pooling2d_2/MaxPool'\nOOM when allocating tensor with shape[224,256,28,28] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential/max_pooling2d_2/MaxPool}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_3552]","output_type":"error"}]}]}